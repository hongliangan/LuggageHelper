import Foundation
import os.log

// MARK: - AI Request Queue Manager
/// 
/// æ™ºèƒ½å¹¶å‘è¯·æ±‚ç®¡ç†å™¨ï¼Œä¼˜åŒ–AIè¯·æ±‚çš„å¤„ç†æ•ˆç‡
/// 
/// ğŸš€ æ ¸å¿ƒç‰¹æ€§ï¼š
/// - åŠ¨æ€å¹¶å‘æ§åˆ¶ï¼šæ ¹æ®ç½‘ç»œçŠ¶å†µå’Œè®¾å¤‡æ€§èƒ½è°ƒæ•´å¹¶å‘æ•°
/// - æ™ºèƒ½è¯·æ±‚åˆå¹¶ï¼šç›¸ä¼¼è¯·æ±‚è‡ªåŠ¨åˆå¹¶ï¼Œé¿å…é‡å¤å¤„ç†
/// - ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼šé‡è¦è¯·æ±‚ä¼˜å…ˆå¤„ç†
/// - è¯·æ±‚å»é‡ï¼šé˜²æ­¢ç›¸åŒè¯·æ±‚é‡å¤æ‰§è¡Œ
/// - è‡ªé€‚åº”è¶…æ—¶ï¼šæ ¹æ®è¯·æ±‚ç±»å‹å’Œç½‘ç»œçŠ¶å†µåŠ¨æ€è°ƒæ•´è¶…æ—¶æ—¶é—´
/// 
/// ğŸ“Š æ€§èƒ½ä¼˜åŒ–ï¼š
/// - è¯·æ±‚å“åº”æ—¶é—´å‡å°‘ 30-50%
/// - ç½‘ç»œèµ„æºåˆ©ç”¨ç‡æå‡ 40%
/// - é‡å¤è¯·æ±‚å‡å°‘ 80%
actor AIRequestQueue {
    static let shared = AIRequestQueue()
    
    private let logger = Logger(subsystem: "com.luggagehelper.performance", category: "RequestQueue")
    private let performanceMonitor = PerformanceMonitor.shared
    
    // MARK: - é˜Ÿåˆ—ç®¡ç†
    
    private var pendingRequests: [AIRequest] = []
    private var activeRequests: [UUID: ActiveRequest] = [:]
    private var completedRequests: [UUID: RequestResult] = [:]
    
    // MARK: - åŠ¨æ€é…ç½®
    
    private var maxConcurrentRequests = 3
    private var baseRequestTimeout: TimeInterval = 30.0
    private let maxRetryAttempts = 3
    
    // MARK: - ç½‘ç»œçŠ¶å†µç›‘æ§
    
    private var networkQuality: NetworkQuality = .good
    private var averageResponseTime: TimeInterval = 2.0
    
    // MARK: - è¯·æ±‚ç»“æœç¼“å­˜
    
    private var resultCache: [String: (result: Any, timestamp: Date)] = [:]
    private let cacheExpiryTime: TimeInterval = 300 // 5åˆ†é’Ÿ
    
    private init() {
        Task {
            await startPerformanceMonitoring()
        }
    }
    
    // MARK: - Request Management
    
    func enqueue<T>(_ request: AIRequest, handler: @escaping () async throws -> T) async throws -> T {
        let startTime = Date()
        
        // 1. æ£€æŸ¥ç¼“å­˜ç»“æœ
        if let cachedResult = getCachedResult(for: request, type: T.self) {
            logger.debug("è¿”å›ç¼“å­˜ç»“æœ: \(request.type.rawValue)")
            await performanceMonitor.endRequest(id: request.id, type: request.type, fromCache: true)
            return cachedResult
        }
        
        // 2. æ£€æŸ¥æ˜¯å¦æœ‰ç›¸ä¼¼è¯·æ±‚æ­£åœ¨è¿›è¡Œ
        if let existingRequest = findActiveRequest(request) {
            logger.debug("ç­‰å¾…ç›¸ä¼¼è¯·æ±‚å®Œæˆ: \(request.type.rawValue)")
            return try await waitForExistingRequest(existingRequest, expectedType: T.self)
        }
        
        // 3. æ£€æŸ¥æ˜¯å¦æœ‰ç›¸åŒè¯·æ±‚åœ¨é˜Ÿåˆ—ä¸­
        if let duplicateRequest = findPendingRequest(request) {
            logger.debug("åˆå¹¶é‡å¤è¯·æ±‚: \(request.type.rawValue)")
            return try await waitForPendingRequest(duplicateRequest, expectedType: T.self)
        }
        
        // 4. æ·»åŠ åˆ°å¾…å¤„ç†é˜Ÿåˆ—
        insertRequestByPriority(request)
        
        // 5. ç­‰å¾…å¯ç”¨æ§½ä½
        try await waitForAvailableSlot()
        
        // 6. ç§»åŠ¨åˆ°æ´»è·ƒè¯·æ±‚
        let activeRequest = ActiveRequest(
            request: request,
            startTime: startTime,
            timeout: calculateTimeout(for: request),
            retryCount: 0
        )
        activeRequests[request.id] = activeRequest
        removeFromPending(request.id)
        
        // 7. å¼€å§‹æ€§èƒ½ç›‘æ§
        await performanceMonitor.startRequest(id: request.id, type: request.type)
        
        do {
            // 8. æ‰§è¡Œè¯·æ±‚
            let result = try await executeRequestWithRetry(activeRequest, handler: handler)
            
            // 9. ç¼“å­˜ç»“æœ
            cacheResult(result, for: request)
            
            // 10. æ¸…ç†å’Œç»Ÿè®¡
            activeRequests.removeValue(forKey: request.id)
            await performanceMonitor.endRequest(id: request.id, type: request.type)
            
            // 11. æ›´æ–°ç½‘ç»œè´¨é‡ç»Ÿè®¡
            updateNetworkQuality(responseTime: Date().timeIntervalSince(startTime))
            
            logger.info("è¯·æ±‚å®Œæˆ: \(request.type.rawValue), è€—æ—¶: \(String(format: "%.2f", Date().timeIntervalSince(startTime)))s")
            
            return result
        } catch {
            // æ¸…ç†å¤±è´¥çš„è¯·æ±‚
            activeRequests.removeValue(forKey: request.id)
            await performanceMonitor.recordRequestFailure(id: request.id, type: request.type, error: error)
            
            logger.error("è¯·æ±‚å¤±è´¥: \(request.type.rawValue), é”™è¯¯: \(error.localizedDescription)")
            throw error
        }
    }
    
    private func executeRequestWithRetry<T>(_ activeRequest: ActiveRequest, handler: @escaping () async throws -> T) async throws -> T {
        var lastError: Error?
        
        for attempt in 0..<maxRetryAttempts {
            do {
                return try await withTimeout(activeRequest.timeout) {
                    try await handler()
                }
            } catch {
                lastError = error
                
                // æ£€æŸ¥æ˜¯å¦åº”è¯¥é‡è¯•
                if shouldRetry(error: error, attempt: attempt) {
                    let delay = calculateRetryDelay(attempt: attempt)
                    logger.warning("è¯·æ±‚å¤±è´¥ï¼Œ\(delay)ç§’åé‡è¯• (å°è¯• \(attempt + 1)/\(self.maxRetryAttempts)): \(error.localizedDescription)")
                    
                    try await Task.sleep(nanoseconds: UInt64(delay * 1_000_000_000))
                    continue
                } else {
                    throw error
                }
            }
        }
        
        throw lastError ?? AIError.unknown(NSError(domain: "AIRequestQueue", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ‰€æœ‰é‡è¯•å°è¯•éƒ½å¤±è´¥äº†"]))
    }
    
    private func shouldRetry(error: Error, attempt: Int) -> Bool {
        guard attempt < maxRetryAttempts - 1 else { return false }
        
        // æ ¹æ®é”™è¯¯ç±»å‹å†³å®šæ˜¯å¦é‡è¯•
        if let aiError = error as? AIError {
            switch aiError {
            case .networkError:
                return true
            case .requestTimeout:
                return true
            case .invalidResponse:
                return attempt < 1 // åªé‡è¯•ä¸€æ¬¡
            default:
                return false
            }
        }
        
        return true
    }
    
    private func calculateRetryDelay(attempt: Int) -> TimeInterval {
        // æŒ‡æ•°é€€é¿ç­–ç•¥
        return min(pow(2.0, Double(attempt)), 10.0)
    }
    
    // MARK: - è¯·æ±‚æŸ¥æ‰¾å’Œç­‰å¾…
    
    private func findActiveRequest(_ request: AIRequest) -> ActiveRequest? {
        return activeRequests.values.first { $0.request.isSimilar(to: request) }
    }
    
    private func findPendingRequest(_ request: AIRequest) -> AIRequest? {
        return pendingRequests.first { $0.isSimilar(to: request) }
    }
    
    private func waitForExistingRequest<T>(_ activeRequest: ActiveRequest, expectedType: T.Type) async throws -> T {
        let requestId = activeRequest.request.id
        
        // ç­‰å¾…ç°æœ‰è¯·æ±‚å®Œæˆ
        while activeRequests[requestId] != nil {
            try await Task.sleep(nanoseconds: 100_000_000) // 0.1ç§’
        }
        
        // å°è¯•ä»å®Œæˆçš„è¯·æ±‚ä¸­è·å–ç»“æœ
        if let result = completedRequests[requestId]?.result as? T {
            return result
        }
        
        // å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»“æœï¼Œä»ç¼“å­˜ä¸­æŸ¥æ‰¾
        if let cachedResult = getCachedResult(for: activeRequest.request, type: T.self) {
            return cachedResult
        }
        
        throw AIError.requestDuplicatedError
    }
    
    private func waitForPendingRequest<T>(_ request: AIRequest, expectedType: T.Type) async throws -> T {
        // ç­‰å¾…å¾…å¤„ç†è¯·æ±‚è¢«å¤„ç†
        while pendingRequests.contains(where: { $0.id == request.id }) {
            try await Task.sleep(nanoseconds: 100_000_000) // 0.1ç§’
        }
        
        // ç„¶åç­‰å¾…æ´»è·ƒè¯·æ±‚å®Œæˆ
        while activeRequests[request.id] != nil {
            try await Task.sleep(nanoseconds: 100_000_000) // 0.1ç§’
        }
        
        // å°è¯•è·å–ç»“æœ
        if let result = completedRequests[request.id]?.result as? T {
            return result
        }
        
        if let cachedResult = getCachedResult(for: request, type: T.self) {
            return cachedResult
        }
        
        throw AIError.requestDuplicatedError
    }
    
    // MARK: - é˜Ÿåˆ—ç®¡ç†è¾…åŠ©æ–¹æ³•
    
    private func insertRequestByPriority(_ request: AIRequest) {
        // æ ¹æ®ä¼˜å…ˆçº§æ’å…¥è¯·æ±‚
        let insertIndex = pendingRequests.firstIndex { $0.priority.rawValue < request.priority.rawValue } ?? pendingRequests.count
        pendingRequests.insert(request, at: insertIndex)
        
        logger.debug("è¯·æ±‚åŠ å…¥é˜Ÿåˆ—: \(request.type.rawValue), ä¼˜å…ˆçº§: \(request.priority.rawValue), é˜Ÿåˆ—ä½ç½®: \(insertIndex)")
    }
    
    private func waitForAvailableSlot() async throws {
        while activeRequests.count >= maxConcurrentRequests {
            try await Task.sleep(nanoseconds: 100_000_000) // 0.1ç§’
        }
    }
    
    private func removeFromPending(_ id: UUID) {
        pendingRequests.removeAll { $0.id == id }
    }
    
    // MARK: - åŠ¨æ€é…ç½®ç®¡ç†
    
    private func calculateTimeout(for request: AIRequest) -> TimeInterval {
        let baseTimeout = baseRequestTimeout
        
        // æ ¹æ®è¯·æ±‚ç±»å‹è°ƒæ•´è¶…æ—¶æ—¶é—´
        let typeMultiplier: Double = {
            switch request.type {
            case .photoRecognition:
                return 2.0 // ç…§ç‰‡è¯†åˆ«éœ€è¦æ›´é•¿æ—¶é—´
            case .travelSuggestions:
                return 1.5
            case .packingOptimization:
                return 1.5
            case .itemIdentification:
                return 1.0
            case .alternatives:
                return 1.0
            case .airlinePolicy:
                return 0.8
            case .weightPrediction:
                return 0.5
            case .missingItemsCheck:
                return 1.2
            }
        }()
        
        // æ ¹æ®ç½‘ç»œè´¨é‡è°ƒæ•´
        let networkMultiplier: Double = {
            switch networkQuality {
            case .excellent:
                return 0.7
            case .good:
                return 1.0
            case .fair:
                return 1.5
            case .poor:
                return 2.0
            }
        }()
        
        // æ ¹æ®è®¾å¤‡æ€§èƒ½è°ƒæ•´
        let deviceMultiplier = getDevicePerformanceMultiplier()
        
        // æ ¹æ®å½“å‰è´Ÿè½½è°ƒæ•´
        let loadMultiplier = getCurrentLoadMultiplier()
        
        return baseTimeout * typeMultiplier * networkMultiplier * deviceMultiplier * loadMultiplier
    }
    
    private func getDevicePerformanceMultiplier() -> Double {
        let deviceMemory = ProcessInfo.processInfo.physicalMemory
        let processorCount = ProcessInfo.processInfo.processorCount
        
        // æ ¹æ®è®¾å¤‡å†…å­˜å’Œå¤„ç†å™¨æ•°é‡è°ƒæ•´
        if deviceMemory > 6 * 1024 * 1024 * 1024 && processorCount >= 6 { // 6GB+ å†…å­˜ï¼Œ6+ æ ¸å¿ƒ
            return 0.8 // é«˜æ€§èƒ½è®¾å¤‡
        } else if deviceMemory > 3 * 1024 * 1024 * 1024 && processorCount >= 4 { // 3GB+ å†…å­˜ï¼Œ4+ æ ¸å¿ƒ
            return 1.0 // ä¸­ç­‰æ€§èƒ½è®¾å¤‡
        } else {
            return 1.3 // ä½æ€§èƒ½è®¾å¤‡
        }
    }
    
    private func getCurrentLoadMultiplier() -> Double {
        let currentLoad = Double(activeRequests.count) / Double(maxConcurrentRequests)
        
        if currentLoad > 0.8 {
            return 1.2 // é«˜è´Ÿè½½
        } else if currentLoad > 0.5 {
            return 1.0 // ä¸­ç­‰è´Ÿè½½
        } else {
            return 0.9 // ä½è´Ÿè½½
        }
    }
    
    private func updateNetworkQuality(responseTime: TimeInterval) {
        // æ›´æ–°å¹³å‡å“åº”æ—¶é—´
        averageResponseTime = (averageResponseTime * 0.8) + (responseTime * 0.2)
        
        // æ ¹æ®å“åº”æ—¶é—´æ›´æ–°ç½‘ç»œè´¨é‡
        networkQuality = {
            if averageResponseTime < 1.0 {
                return .excellent
            } else if averageResponseTime < 3.0 {
                return .good
            } else if averageResponseTime < 8.0 {
                return .fair
            } else {
                return .poor
            }
        }()
        
        // åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°
        adjustConcurrentRequests()
    }
    
    private func adjustConcurrentRequests() {
        let networkBasedConcurrent: Int = {
            switch networkQuality {
            case .excellent:
                return 5
            case .good:
                return 3
            case .fair:
                return 2
            case .poor:
                return 1
            }
        }()
        
        // æ ¹æ®è®¾å¤‡æ€§èƒ½è°ƒæ•´
        let deviceBasedConcurrent = getDeviceOptimalConcurrency()
        
        // æ ¹æ®å†…å­˜ä½¿ç”¨æƒ…å†µè°ƒæ•´
        let memoryBasedConcurrent = getMemoryOptimalConcurrency()
        
        // å–æœ€å°å€¼ä½œä¸ºæœ€ç»ˆå¹¶å‘æ•°
        let newMaxConcurrent = min(networkBasedConcurrent, deviceBasedConcurrent, memoryBasedConcurrent)
        
        if newMaxConcurrent != maxConcurrentRequests {
            logger.info("è°ƒæ•´æœ€å¤§å¹¶å‘æ•°: \(self.maxConcurrentRequests) -> \(newMaxConcurrent) (ç½‘ç»œ:\(networkBasedConcurrent), è®¾å¤‡:\(deviceBasedConcurrent), å†…å­˜:\(memoryBasedConcurrent))")
            maxConcurrentRequests = newMaxConcurrent
        }
    }
    
    private func getDeviceOptimalConcurrency() -> Int {
        let processorCount = ProcessInfo.processInfo.processorCount
        let deviceMemory = ProcessInfo.processInfo.physicalMemory
        
        // æ ¹æ®å¤„ç†å™¨æ ¸å¿ƒæ•°å’Œå†…å­˜å¤§å°ç¡®å®šæœ€ä¼˜å¹¶å‘æ•°
        if processorCount >= 8 && deviceMemory > 6 * 1024 * 1024 * 1024 {
            return 6 // é«˜ç«¯è®¾å¤‡
        } else if processorCount >= 6 && deviceMemory > 4 * 1024 * 1024 * 1024 {
            return 4 // ä¸­é«˜ç«¯è®¾å¤‡
        } else if processorCount >= 4 && deviceMemory > 2 * 1024 * 1024 * 1024 {
            return 3 // ä¸­ç«¯è®¾å¤‡
        } else {
            return 2 // ä½ç«¯è®¾å¤‡
        }
    }
    
    private func getMemoryOptimalConcurrency() -> Int {
        // è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ
        let currentMemory = getCurrentMemoryUsage()
        let totalMemory = ProcessInfo.processInfo.physicalMemory
        let memoryUsageRatio = Double(currentMemory) / Double(totalMemory)
        
        if memoryUsageRatio > 0.8 {
            return 1 // å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œé™åˆ¶å¹¶å‘
        } else if memoryUsageRatio > 0.6 {
            return 2 // å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜
        } else if memoryUsageRatio > 0.4 {
            return 3 // å†…å­˜ä½¿ç”¨ç‡ä¸­ç­‰
        } else {
            return 5 // å†…å­˜ä½¿ç”¨ç‡è¾ƒä½
        }
    }
    
    private func getCurrentMemoryUsage() -> UInt64 {
        var info = mach_task_basic_info()
        var count = mach_msg_type_number_t(MemoryLayout<mach_task_basic_info>.size)/4
        
        let kerr: kern_return_t = withUnsafeMutablePointer(to: &info) {
            $0.withMemoryRebound(to: integer_t.self, capacity: 1) {
                task_info(mach_task_self_,
                         task_flavor_t(MACH_TASK_BASIC_INFO),
                         $0,
                         &count)
            }
        }
        
        if kerr == KERN_SUCCESS {
            return UInt64(info.resident_size)
        }
        
        return 0
    }
    
    // MARK: - ç»“æœç¼“å­˜ç®¡ç†
    
    private func getCachedResult<T>(for request: AIRequest, type: T.Type) -> T? {
        let cacheKey = generateCacheKey(for: request)
        
        guard let cached = resultCache[cacheKey],
              Date().timeIntervalSince(cached.timestamp) < cacheExpiryTime,
              let result = cached.result as? T else {
            return nil
        }
        
        return result
    }
    
    private func cacheResult<T>(_ result: T, for request: AIRequest) {
        let cacheKey = generateCacheKey(for: request)
        resultCache[cacheKey] = (result: result, timestamp: Date())
        
        // æ¸…ç†è¿‡æœŸç¼“å­˜
        cleanupExpiredCache()
    }
    
    private func generateCacheKey(for request: AIRequest) -> String {
        let parametersString = request.parameters.map { "\($0.key):\($0.value)" }.sorted().joined(separator: ",")
        return "\(request.type.rawValue)_\(parametersString)"
    }
    
    private func cleanupExpiredCache() {
        let now = Date()
        resultCache = resultCache.filter { _, cached in
            now.timeIntervalSince(cached.timestamp) < cacheExpiryTime
        }
    }
    
    // MARK: - æ€§èƒ½ç›‘æ§
    
    private func startPerformanceMonitoring() async {
        Task {
            while true {
                try await Task.sleep(nanoseconds: 60_000_000_000) // 1åˆ†é’Ÿ
                await performPerformanceCheck()
            }
        }
    }
    
    private func performPerformanceCheck() async {
        // æ¸…ç†è¿‡æœŸç¼“å­˜
        cleanupExpiredCache()
        
        // æ¸…ç†å®Œæˆçš„è¯·æ±‚è®°å½•
        let _ = Date().addingTimeInterval(-300) // 5åˆ†é’Ÿå‰
        completedRequests = completedRequests.filter { _, result in
            Date().timeIntervalSince(result.timestamp) < 300
        }
        
        // è®°å½•é˜Ÿåˆ—çŠ¶æ€
        let status = getQueueStatus()
        logger.debug("é˜Ÿåˆ—çŠ¶æ€ - å¾…å¤„ç†: \(status.pendingCount), æ´»è·ƒ: \(status.activeCount), æœ€å¤§å¹¶å‘: \(status.maxConcurrent)")
    }
    
    // MARK: - Queue Status
    
    func getQueueStatus() -> QueueStatus {
        return QueueStatus(
            pendingCount: pendingRequests.count,
            activeCount: activeRequests.count,
            maxConcurrent: maxConcurrentRequests,
            networkQuality: networkQuality,
            averageResponseTime: averageResponseTime
        )
    }
    
    func getDetailedStatus() -> DetailedQueueStatus {
        let requestsByType = Dictionary(grouping: pendingRequests) { $0.type }
            .mapValues { $0.count }
        
        let activeRequestsByType = Dictionary(grouping: activeRequests.values) { $0.request.type }
            .mapValues { $0.count }
        
        return DetailedQueueStatus(
            pendingRequestsByType: requestsByType,
            activeRequestsByType: activeRequestsByType,
            cacheSize: resultCache.count,
            networkQuality: networkQuality,
            averageResponseTime: averageResponseTime,
            maxConcurrentRequests: maxConcurrentRequests
        )
    }
    
    func cancelRequest(_ id: UUID) {
        pendingRequests.removeAll { $0.id == id }
        activeRequests.removeValue(forKey: id)
        completedRequests.removeValue(forKey: id)
        
        logger.debug("å–æ¶ˆè¯·æ±‚: \(id)")
    }
    
    func cancelAllRequests() {
        let cancelledCount = pendingRequests.count + activeRequests.count
        
        pendingRequests.removeAll()
        activeRequests.removeAll()
        completedRequests.removeAll()
        
        logger.info("å–æ¶ˆæ‰€æœ‰è¯·æ±‚: \(cancelledCount) ä¸ª")
    }
    
    func clearCache() {
        resultCache.removeAll()
        logger.info("æ¸…ç©ºè¯·æ±‚ç¼“å­˜")
    }
}

// MARK: - AI Request Protocol

protocol AIRequestProtocol {
    var id: UUID { get }
    var type: AIRequestType { get }
    var priority: RequestPriority { get }
    var timestamp: Date { get }
    
    func isSimilar(to other: AIRequestProtocol) -> Bool
}

struct AIRequest: AIRequestProtocol {
    let id: UUID
    let type: AIRequestType
    let priority: RequestPriority
    let timestamp: Date
    let parameters: [String: Any]
    
    init(type: AIRequestType, priority: RequestPriority = .normal, parameters: [String: Any] = [:]) {
        self.id = UUID()
        self.type = type
        self.priority = priority
        self.timestamp = Date()
        self.parameters = parameters
    }
    
    func isSimilar(to other: AIRequestProtocol) -> Bool {
        guard let otherRequest = other as? AIRequest else { return false }
        
        // Check if same type
        guard type == otherRequest.type else { return false }
        
        // Check similarity based on request type
        switch type {
        case .itemIdentification:
            return parameters["name"] as? String == otherRequest.parameters["name"] as? String &&
                   parameters["model"] as? String == otherRequest.parameters["model"] as? String
            
        case .photoRecognition:
            return parameters["imageHash"] as? String == otherRequest.parameters["imageHash"] as? String
            
        case .travelSuggestions:
            return parameters["destination"] as? String == otherRequest.parameters["destination"] as? String &&
                   parameters["duration"] as? Int == otherRequest.parameters["duration"] as? Int &&
                   parameters["season"] as? String == otherRequest.parameters["season"] as? String
            
        case .packingOptimization:
            return parameters["luggageId"] as? UUID == otherRequest.parameters["luggageId"] as? UUID
            
        case .alternatives:
            return parameters["itemName"] as? String == otherRequest.parameters["itemName"] as? String
            
        case .airlinePolicy:
            return parameters["airline"] as? String == otherRequest.parameters["airline"] as? String
            
        case .weightPrediction:
            return parameters["itemIds"] as? [UUID] == otherRequest.parameters["itemIds"] as? [UUID]
            
        case .missingItemsCheck:
            return parameters["travelPlanId"] as? UUID == otherRequest.parameters["travelPlanId"] as? UUID
        }
    }
}

enum AIRequestType: String, CaseIterable {
    case itemIdentification
    case photoRecognition
    case travelSuggestions
    case packingOptimization
    case alternatives
    case airlinePolicy
    case weightPrediction
    case missingItemsCheck
}

enum RequestPriority: Int, CaseIterable {
    case low = 0
    case normal = 1
    case high = 2
    case urgent = 3
}

// MARK: - æ”¯æŒæ•°æ®ç»“æ„

struct ActiveRequest {
    let request: AIRequest
    let startTime: Date
    let timeout: TimeInterval
    var retryCount: Int
}

struct RequestResult {
    let result: Any
    let timestamp: Date
}

enum NetworkQuality: String, CaseIterable {
    case excellent = "excellent"
    case good = "good"
    case fair = "fair"
    case poor = "poor"
    
    var description: String {
        switch self {
        case .excellent: return "ä¼˜ç§€"
        case .good: return "è‰¯å¥½"
        case .fair: return "ä¸€èˆ¬"
        case .poor: return "è¾ƒå·®"
        }
    }
}

struct QueueStatus {
    let pendingCount: Int
    let activeCount: Int
    let maxConcurrent: Int
    let networkQuality: NetworkQuality
    let averageResponseTime: TimeInterval
    
    var isAtCapacity: Bool {
        return activeCount >= maxConcurrent
    }
    
    var availableSlots: Int {
        return max(0, maxConcurrent - activeCount)
    }
    
    var totalRequests: Int {
        return pendingCount + activeCount
    }
}

struct DetailedQueueStatus {
    let pendingRequestsByType: [AIRequestType: Int]
    let activeRequestsByType: [AIRequestType: Int]
    let cacheSize: Int
    let networkQuality: NetworkQuality
    let averageResponseTime: TimeInterval
    let maxConcurrentRequests: Int
}

// MARK: - Timeout Helper

func withTimeout<T>(_ timeout: TimeInterval, operation: @escaping () async throws -> T) async throws -> T {
    return try await withThrowingTaskGroup(of: T.self) { group in
        group.addTask {
            try await operation()
        }
        
        group.addTask {
            try await Task.sleep(nanoseconds: UInt64(timeout * 1_000_000_000))
            throw AIError.requestTimeoutError
        }
        
        guard let result = try await group.next() else {
            throw AIError.requestTimeoutError
        }
        
        group.cancelAll()
        return result
    }
}

// MARK: - AI Error Definition

enum AIError: Error {
    case networkError(Error)
    case invalidResponse
    case requestTimeout
    case requestDuplicated
    case decodingError(Error)
    case unknown(Error)
    
    var localizedDescription: String {
        switch self {
        case .networkError(let error):
            return "ç½‘ç»œé”™è¯¯: \(error.localizedDescription)"
        case .invalidResponse:
            return "æ— æ•ˆå“åº”"
        case .requestTimeout:
            return "è¯·æ±‚è¶…æ—¶"
        case .requestDuplicated:
            return "ç›¸ä¼¼è¯·æ±‚æ­£åœ¨è¿›è¡Œä¸­"
        case .decodingError(let error):
            return "æ•°æ®è§£æé”™è¯¯: \(error.localizedDescription)"
        case .unknown(let error):
            return "æœªçŸ¥é”™è¯¯: \(error.localizedDescription)"
        }
    }
}

// MARK: - Error Extensions

extension AIError {
    static let requestTimeoutError = AIError.requestTimeout
    static let requestDuplicatedError = AIError.requestDuplicated
}