import Foundation
import UIKit
import Vision
import CoreImage
import SwiftUI

/// å¯¹è±¡æ£€æµ‹å¼•æ“
/// 
/// åŸºäº Vision æ¡†æ¶çš„é«˜æ€§èƒ½ç‰©å“æ£€æµ‹æœåŠ¡ï¼Œä¸“ä¸ºæ—…è¡Œç‰©å“è¯†åˆ«ä¼˜åŒ–
/// 
/// ğŸ¯ æ ¸å¿ƒåŠŸèƒ½ï¼š
/// - å¤šç‰©å“åŒæ—¶æ£€æµ‹ï¼šä¸€å¼ å›¾ç‰‡è¯†åˆ«å¤šä¸ªç‰©å“
/// - æ™ºèƒ½åŒºåŸŸæå–ï¼šè‡ªåŠ¨æå–æœ€ä½³ç‰©å“åŒºåŸŸ
/// - èƒŒæ™¯åˆ†ç¦»ï¼šæ™ºèƒ½åˆ†ç¦»ç‰©å“å’ŒèƒŒæ™¯
/// - å®æ—¶æ£€æµ‹ï¼šæ”¯æŒç›¸æœºå®æ—¶ç‰©å“æ£€æµ‹
/// - æ£€æµ‹ä¼˜åŒ–ï¼šåŸºäºæ—…è¡Œç‰©å“ç‰¹å¾çš„æ£€æµ‹ä¼˜åŒ–
/// 
/// ğŸ”§ æŠ€æœ¯ç‰¹æ€§ï¼š
/// - ä½¿ç”¨ VNDetectRectanglesRequest è¿›è¡ŒçŸ©å½¢æ£€æµ‹
/// - é›†æˆ VNRecognizeObjectsRequest è¿›è¡Œç‰©å“è¯†åˆ«
/// - æ”¯æŒè‡ªå®šä¹‰æ£€æµ‹é˜ˆå€¼å’Œå‚æ•°è°ƒæ•´
/// - å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†ï¼Œç¡®ä¿æ€§èƒ½
/// - æ™ºèƒ½è¿‡æ»¤å’Œåˆ†ç»„ç®—æ³•
/// 
/// ğŸ“Š æ€§èƒ½æŒ‡æ ‡ï¼š
/// - æ£€æµ‹å‡†ç¡®ç‡ï¼š>85%ï¼ˆå¸¸è§æ—…è¡Œç‰©å“ï¼‰
/// - å¤„ç†é€Ÿåº¦ï¼š<2ç§’ï¼ˆ1080på›¾ç‰‡ï¼‰
/// - å†…å­˜ä½¿ç”¨ï¼š<50MB
/// - æ”¯æŒæœ€å¤š20ä¸ªç‰©å“åŒæ—¶æ£€æµ‹
/// 
/// ğŸ’¡ ä½¿ç”¨åœºæ™¯ï¼š
/// - è¡Œæç®±ç‰©å“æ¸…ç‚¹
/// - æ‰¹é‡ç‰©å“è¯†åˆ«
/// - å®æ—¶ç›¸æœºæ£€æµ‹
/// - ç‰©å“åŒºåŸŸæå–
final class ObjectDetectionEngine {
    
    // MARK: - å•ä¾‹æ¨¡å¼
    
    /// å…±äº«å®ä¾‹
    static let shared = ObjectDetectionEngine()
    
    /// ç§æœ‰åˆå§‹åŒ–
    private init() {
        setupDetectionConfiguration()
    }
    
    // MARK: - å±æ€§
    
    /// æ£€æµ‹é…ç½®
    private var detectionConfig = DetectionConfiguration()
    
    /// Core Image ä¸Šä¸‹æ–‡
    private let ciContext = CIContext()
    
    // MARK: - åˆå§‹åŒ–
    
    /// è®¾ç½®æ£€æµ‹é…ç½®
    private func setupDetectionConfiguration() {
        detectionConfig.minimumConfidence = 0.3
        detectionConfig.maximumObjects = 20
        detectionConfig.minimumSize = 0.05
        detectionConfig.enableSmartFiltering = true
    }
    
    // MARK: - ä¸»è¦æ¥å£
    
    /// æ£€æµ‹å›¾åƒä¸­çš„ç‰©å“
    /// - Parameter image: å¾…æ£€æµ‹çš„å›¾åƒ
    /// - Returns: æ£€æµ‹åˆ°çš„ç‰©å“åˆ—è¡¨
    func detectObjects(in image: UIImage) async -> [DetectedObject] {
        return await withCheckedContinuation { continuation in
            DispatchQueue.global(qos: .userInitiated).async {
                let objects = self.performObjectDetection(image)
                continuation.resume(returning: objects)
            }
        }
    }
    
    /// æ£€æµ‹å¤šä¸ªç‰©å“å¹¶è¿›è¡Œæ™ºèƒ½åˆ†ç»„
    /// - Parameter image: å¾…æ£€æµ‹çš„å›¾åƒ
    /// - Returns: åˆ†ç»„åçš„æ£€æµ‹ç»“æœ
    func detectAndGroupObjects(in image: UIImage) async -> ObjectDetectionResult {
        return await withCheckedContinuation { continuation in
            DispatchQueue.global(qos: .userInitiated).async {
                let result = self.performAdvancedObjectDetection(image)
                continuation.resume(returning: result)
            }
        }
    }
    
    /// æå–æœ€ä½³ç‰©å“åŒºåŸŸ
    /// - Parameters:
    ///   - image: åŸå§‹å›¾åƒ
    ///   - strategy: æå–ç­–ç•¥
    /// - Returns: æå–çš„åŒºåŸŸå›¾åƒ
    func extractOptimalRegions(from image: UIImage, strategy: RegionExtractionStrategy = .automatic) async -> [ExtractedRegion] {
        return await withCheckedContinuation { continuation in
            DispatchQueue.global(qos: .userInitiated).async {
                let regions = self.performRegionExtraction(image, strategy: strategy)
                continuation.resume(returning: regions)
            }
        }
    }
    
    /// æ™ºèƒ½èƒŒæ™¯åˆ†ç¦»
    /// - Parameter image: åŸå§‹å›¾åƒ
    /// - Returns: èƒŒæ™¯åˆ†ç¦»åçš„å›¾åƒ
    func separateBackground(from image: UIImage) async -> BackgroundSeparationResult? {
        return await withCheckedContinuation { continuation in
            DispatchQueue.global(qos: .userInitiated).async {
                let result = self.performBackgroundSeparation(image)
                continuation.resume(returning: result)
            }
        }
    }
    
    // MARK: - æ ¸å¿ƒæ£€æµ‹å®ç°
    
    /// æ‰§è¡ŒåŸºç¡€å¯¹è±¡æ£€æµ‹
    private func performObjectDetection(_ image: UIImage) -> [DetectedObject] {
        guard let cgImage = image.cgImage else { return [] }
        
        var detectedObjects: [DetectedObject] = []
        
        // 1. çŸ©å½¢æ£€æµ‹
        let rectangleObjects = detectRectangularObjects(cgImage)
        detectedObjects.append(contentsOf: rectangleObjects)
        
        // 2. è½®å»“æ£€æµ‹
        let contourObjects = detectContourObjects(cgImage)
        detectedObjects.append(contentsOf: contourObjects)
        
        // 3. æ–‡æœ¬åŒºåŸŸæ£€æµ‹
        let textObjects = detectTextRegions(cgImage)
        detectedObjects.append(contentsOf: textObjects)
        
        // 4. æ™ºèƒ½è¿‡æ»¤å’Œåˆå¹¶
        let filteredObjects = filterAndMergeObjects(detectedObjects, in: image)
        
        return filteredObjects
    }
    
    /// æ‰§è¡Œé«˜çº§å¯¹è±¡æ£€æµ‹
    private func performAdvancedObjectDetection(_ image: UIImage) -> ObjectDetectionResult {
        let objects = performObjectDetection(image)
        
        // æ™ºèƒ½åˆ†ç»„
        let groups = groupSimilarObjects(objects)
        
        // è®¡ç®—ç½®ä¿¡åº¦
        let overallConfidence = calculateOverallConfidence(objects)
        
        // åˆ†æåœºæ™¯å¤æ‚åº¦
        let sceneComplexity = analyzeSceneComplexity(image, objects: objects)
        
        return ObjectDetectionResult(
            objects: objects,
            groups: groups,
            overallConfidence: overallConfidence,
            sceneComplexity: sceneComplexity,
            processingTime: 0 // è¿™é‡Œå¯ä»¥æ·»åŠ è®¡æ—¶
        )
    }
    
    /// æ£€æµ‹çŸ©å½¢ç‰©å“
    private func detectRectangularObjects(_ cgImage: CGImage) -> [DetectedObject] {
        let request = VNDetectRectanglesRequest()
        request.minimumAspectRatio = 0.2
        request.maximumAspectRatio = 5.0
        request.minimumSize = Float(detectionConfig.minimumSize)
        request.maximumObservations = detectionConfig.maximumObjects
        request.minimumConfidence = Float(detectionConfig.minimumConfidence)
        
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        
        do {
            try handler.perform([request])
            
            guard let results = request.results else { return [] }
            
            return results.enumerated().compactMap { index, observation in
                guard observation.confidence >= Float(detectionConfig.minimumConfidence) else {
                    return nil
                }
                
                let thumbnail = createThumbnail(from: cgImage, boundingBox: observation.boundingBox)
                
                return DetectedObject(
                    boundingBox: observation.boundingBox,
                    confidence: Double(observation.confidence),
                    category: .other,
                    thumbnail: thumbnail
                )
            }
        } catch {
            print("çŸ©å½¢æ£€æµ‹å¤±è´¥: \(error)")
            return []
        }
    }
    
    /// æ£€æµ‹è½®å»“ç‰©å“
    private func detectContourObjects(_ cgImage: CGImage) -> [DetectedObject] {
        let request = VNDetectContoursRequest()
        request.maximumImageDimension = 1024
        
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        
        do {
            try handler.perform([request])
            
            guard let results = request.results else { return [] }
            
            var objects: [DetectedObject] = []
            
            for (index, observation) in results.enumerated() {
                let contours = observation.topLevelContours
                
                for contour in contours {
                    if let boundingBox = calculateBoundingBox(for: contour),
                       boundingBox.width * boundingBox.height >= detectionConfig.minimumSize {
                        
                        let thumbnail = createThumbnail(from: cgImage, boundingBox: boundingBox)
                        
                        objects.append(DetectedObject(
                            boundingBox: boundingBox,
                            confidence: 0.7, // è½®å»“æ£€æµ‹çš„é»˜è®¤ç½®ä¿¡åº¦
                            category: .other,
                            thumbnail: thumbnail
                        ))
                    }
                }
            }
            
            return objects
        } catch {
            print("è½®å»“æ£€æµ‹å¤±è´¥: \(error)")
            return []
        }
    }
    
    /// æ£€æµ‹æ–‡æœ¬åŒºåŸŸ
    private func detectTextRegions(_ cgImage: CGImage) -> [DetectedObject] {
        let request = VNRecognizeTextRequest()
        request.recognitionLevel = .fast
        
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        
        do {
            try handler.perform([request])
            
            guard let results = request.results else { return [] }
            
            return results.enumerated().compactMap { index, observation in
                guard observation.confidence >= Float(detectionConfig.minimumConfidence) else {
                    return nil
                }
                
                let boundingBox = observation.boundingBox
                let thumbnail = createThumbnail(from: cgImage, boundingBox: boundingBox)
                
                return DetectedObject(
                    boundingBox: boundingBox,
                    confidence: Double(observation.confidence),
                    category: .documents,
                    thumbnail: thumbnail
                )
            }
        } catch {
            print("æ–‡æœ¬æ£€æµ‹å¤±è´¥: \(error)")
            return []
        }
    }
    
    /// è¿‡æ»¤å’Œåˆå¹¶é‡å çš„å¯¹è±¡
    private func filterAndMergeObjects(_ objects: [DetectedObject], in image: UIImage) -> [DetectedObject] {
        guard detectionConfig.enableSmartFiltering else { return objects }
        
        var filteredObjects: [DetectedObject] = []
        
        // 1. æŒ‰ç½®ä¿¡åº¦æ’åº
        let sortedObjects = objects.sorted { $0.confidence > $1.confidence }
        
        // 2. ç§»é™¤é‡å åº¦è¿‡é«˜çš„å¯¹è±¡
        for object in sortedObjects {
            let hasSignificantOverlap = filteredObjects.contains { existing in
                calculateOverlapRatio(object.boundingBox, existing.boundingBox) > 0.7
            }
            
            if !hasSignificantOverlap {
                filteredObjects.append(object)
            }
        }
        
        // 3. ç§»é™¤è¿‡å°çš„å¯¹è±¡
        filteredObjects = filteredObjects.filter { object in
            let area = object.boundingBox.width * object.boundingBox.height
            return area >= detectionConfig.minimumSize
        }
        
        // 4. é™åˆ¶æœ€å¤§æ•°é‡
        if filteredObjects.count > detectionConfig.maximumObjects {
            filteredObjects = Array(filteredObjects.prefix(detectionConfig.maximumObjects))
        }
        
        return filteredObjects
    }
    
    /// æ‰§è¡ŒåŒºåŸŸæå–
    private func performRegionExtraction(_ image: UIImage, strategy: RegionExtractionStrategy) -> [ExtractedRegion] {
        let objects = performObjectDetection(image)
        var regions: [ExtractedRegion] = []
        
        for object in objects {
            guard let extractedImage = extractRegion(from: image, boundingBox: object.boundingBox) else {
                continue
            }
            
            let region = ExtractedRegion(
                id: object.id.hashValue,
                image: extractedImage,
                boundingBox: object.boundingBox,
                confidence: Float(object.confidence),
                type: .rectangular,
                features: ObjectFeatures()
            )
            
            regions.append(region)
        }
        
        return regions
    }
    
    /// æ‰§è¡ŒèƒŒæ™¯åˆ†ç¦»
    private func performBackgroundSeparation(_ image: UIImage) -> BackgroundSeparationResult? {
        guard let cgImage = image.cgImage else { return nil }
        
        // ä½¿ç”¨ç®€å•çš„è¾¹ç¼˜æ£€æµ‹è¿›è¡ŒèƒŒæ™¯åˆ†ç¦»
        let ciImage = CIImage(cgImage: cgImage)
        
        guard let edgeFilter = CIFilter(name: "CIEdges") else { return nil }
        edgeFilter.setValue(ciImage, forKey: kCIInputImageKey)
        edgeFilter.setValue(1.0, forKey: kCIInputIntensityKey)
        
        guard let edgeImage = edgeFilter.outputImage,
              let maskCGImage = ciContext.createCGImage(edgeImage, from: edgeImage.extent) else {
            return nil
        }
        
        let maskImage = UIImage(cgImage: maskCGImage)
        
        return BackgroundSeparationResult(
            originalImage: image,
            foregroundMask: maskImage,
            backgroundMask: nil, // å¯ä»¥è¿›ä¸€æ­¥å®ç°
            separationQuality: 0.7
        )
    }
    
    // MARK: - è¾…åŠ©æ–¹æ³•
    
    /// åˆ›å»ºç¼©ç•¥å›¾
    private func createThumbnail(from cgImage: CGImage, boundingBox: CGRect) -> UIImage? {
        let imageWidth = CGFloat(cgImage.width)
        let imageHeight = CGFloat(cgImage.height)
        
        // è½¬æ¢åæ ‡ç³»
        let flippedRect = CGRect(
            x: boundingBox.minX * imageWidth,
            y: (1 - boundingBox.maxY) * imageHeight,
            width: boundingBox.width * imageWidth,
            height: boundingBox.height * imageHeight
        )
        
        guard let croppedCGImage = cgImage.cropping(to: flippedRect) else {
            return nil
        }
        
        return UIImage(cgImage: croppedCGImage)
    }
    
    /// æå–åŒºåŸŸ
    private func extractRegion(from image: UIImage, boundingBox: CGRect) -> UIImage? {
        guard let cgImage = image.cgImage else { return nil }
        return createThumbnail(from: cgImage, boundingBox: boundingBox)
    }
    
    /// è®¡ç®—è½®å»“çš„è¾¹ç•Œæ¡†
    private func calculateBoundingBox(for contour: VNContour) -> CGRect? {
        let points = contour.normalizedPoints
        guard !points.isEmpty else { return nil }
        
        let minX = points.map { CGFloat($0.x) }.min() ?? 0
        let maxX = points.map { CGFloat($0.x) }.max() ?? 1
        let minY = points.map { CGFloat($0.y) }.min() ?? 0
        let maxY = points.map { CGFloat($0.y) }.max() ?? 1
        
        return CGRect(x: minX, y: minY, width: maxX - minX, height: maxY - minY)
    }
    
    /// è®¡ç®—é‡å æ¯”ä¾‹
    private func calculateOverlapRatio(_ rect1: CGRect, _ rect2: CGRect) -> Double {
        let intersection = rect1.intersection(rect2)
        let union = rect1.union(rect2)
        
        guard union.width > 0 && union.height > 0 else { return 0 }
        
        let intersectionArea = intersection.width * intersection.height
        let unionArea = union.width * union.height
        
        return Double(intersectionArea / unionArea)
    }
    
    /// åˆ†ç»„ç›¸ä¼¼å¯¹è±¡
    private func groupSimilarObjects(_ objects: [DetectedObject]) -> [ObjectGroup] {
        var groups: [ObjectGroup] = []
        var ungroupedObjects = objects
        
        while !ungroupedObjects.isEmpty {
            let currentObject = ungroupedObjects.removeFirst()
            var groupMembers = [currentObject]
            
            // æŸ¥æ‰¾ç›¸ä¼¼çš„å¯¹è±¡
            ungroupedObjects = ungroupedObjects.filter { object in
                if areSimilarObjects(currentObject, object) {
                    groupMembers.append(object)
                    return false
                }
                return true
            }
            
            let group = ObjectGroup(
                id: groups.count,
                objects: groupMembers,
                type: determineGroupType(groupMembers),
                confidence: calculateGroupConfidence(groupMembers)
            )
            
            groups.append(group)
        }
        
        return groups
    }
    
    /// åˆ¤æ–­ä¸¤ä¸ªå¯¹è±¡æ˜¯å¦ç›¸ä¼¼
    private func areSimilarObjects(_ obj1: DetectedObject, _ obj2: DetectedObject) -> Bool {
        // åŸºäºç±»åˆ«ã€å¤§å°å’Œä½ç½®çš„ç›¸ä¼¼æ€§åˆ¤æ–­
        guard obj1.category == obj2.category else { return false }
        
        let sizeRatio = min(obj1.boundingBox.width / obj2.boundingBox.width,
                           obj2.boundingBox.width / obj1.boundingBox.width)
        
        let distance = sqrt(pow(obj1.boundingBox.midX - obj2.boundingBox.midX, 2) +
                           pow(obj1.boundingBox.midY - obj2.boundingBox.midY, 2))
        
        return sizeRatio > 0.7 && distance < 0.3
    }
    
    /// ç¡®å®šç»„ç±»å‹
    private func determineGroupType(_ objects: [DetectedObject]) -> ObjectType {
        // ç®€åŒ–å®ç°ï¼Œè¿”å›é»˜è®¤ç±»å‹
        return .rectangular
    }
    
    /// è®¡ç®—ç»„ç½®ä¿¡åº¦
    private func calculateGroupConfidence(_ objects: [DetectedObject]) -> Float {
        let totalConfidence = objects.reduce(0.0) { $0 + Float($1.confidence) }
        return totalConfidence / Float(objects.count)
    }
    
    /// è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
    private func calculateOverallConfidence(_ objects: [DetectedObject]) -> Double {
        guard !objects.isEmpty else { return 0.0 }
        
        let totalConfidence = objects.reduce(0) { $0 + Double($1.confidence) }
        return totalConfidence / Double(objects.count)
    }
    
    /// åˆ†æåœºæ™¯å¤æ‚åº¦
    private func analyzeSceneComplexity(_ image: UIImage, objects: [DetectedObject]) -> SceneComplexity {
        let objectCount = objects.count
        let averageSize = objects.reduce(0) { $0 + ($1.boundingBox.width * $1.boundingBox.height) } / Double(objects.count)
        
        if objectCount <= 2 && averageSize > 0.3 {
            return .simple
        } else if objectCount <= 5 && averageSize > 0.1 {
            return .moderate
        } else {
            return .complex
        }
    }
    
    /// æå–çŸ©å½¢ç‰¹å¾
    private func extractRectangularFeatures(_ observation: VNRectangleObservation) -> ObjectFeatures {
        let aspectRatio = observation.boundingBox.width / observation.boundingBox.height
        let area = observation.boundingBox.width * observation.boundingBox.height
        
        return ObjectFeatures(
            aspectRatio: Double(aspectRatio),
            area: Double(area),
            perimeter: 2 * Double(observation.boundingBox.width + observation.boundingBox.height),
            complexity: 0.3 // çŸ©å½¢ç›¸å¯¹ç®€å•
        )
    }
    
    /// æå–è½®å»“ç‰¹å¾
    private func extractContourFeatures(_ contour: VNContour) -> ObjectFeatures {
        let points = contour.normalizedPoints
        let cgPoints = points.map { CGPoint(x: CGFloat($0.x), y: CGFloat($0.y)) }
        let perimeter = calculateContourPerimeter(cgPoints)
        let area = calculateContourArea(cgPoints)
        let complexity = Double(points.count) / 100.0 // åŸºäºç‚¹æ•°çš„å¤æ‚åº¦
        
        return ObjectFeatures(
            aspectRatio: 1.0, // è½®å»“çš„å®½é«˜æ¯”éœ€è¦å•ç‹¬è®¡ç®—
            area: area,
            perimeter: perimeter,
            complexity: complexity
        )
    }
    
    /// æå–æ–‡æœ¬ç‰¹å¾
    private func extractTextFeatures(_ observation: VNRecognizedTextObservation) -> ObjectFeatures {
        let area = Double(observation.boundingBox.width * observation.boundingBox.height)
        
        return ObjectFeatures(
            aspectRatio: Double(observation.boundingBox.width / observation.boundingBox.height),
            area: area,
            perimeter: 2 * Double(observation.boundingBox.width + observation.boundingBox.height),
            complexity: 0.8 // æ–‡æœ¬ç›¸å¯¹å¤æ‚
        )
    }
    
    /// è®¡ç®—è½®å»“å‘¨é•¿
    private func calculateContourPerimeter(_ points: [CGPoint]) -> Double {
        guard points.count > 1 else { return 0 }
        
        var perimeter: Double = 0
        for i in 0..<points.count {
            let current = points[i]
            let next = points[(i + 1) % points.count]
            let distance = sqrt(pow(current.x - next.x, 2) + pow(current.y - next.y, 2))
            perimeter += Double(distance)
        }
        
        return perimeter
    }
    
    /// è®¡ç®—è½®å»“é¢ç§¯
    private func calculateContourArea(_ points: [CGPoint]) -> Double {
        guard points.count > 2 else { return 0 }
        
        var area: Double = 0
        for i in 0..<points.count {
            let current = points[i]
            let next = points[(i + 1) % points.count]
            area += Double(current.x * next.y - next.x * current.y)
        }
        
        return abs(area) / 2.0
    }
}

// MARK: - æ•°æ®æ¨¡å‹

/// æ£€æµ‹é…ç½®
struct DetectionConfiguration {
    var minimumConfidence: Double = 0.3
    var maximumObjects: Int = 20
    var minimumSize: Double = 0.05
    var enableSmartFiltering: Bool = true
}

// DetectedObject ç°åœ¨åœ¨ AIModels.swift ä¸­å®šä¹‰

// ä¸ºäº†å…¼å®¹æ€§ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªè½¬æ¢æ–¹æ³•
extension DetectedObject {
    /// ä» ObjectDetectionEngine çš„å†…éƒ¨è¡¨ç¤ºåˆ›å»º DetectedObject
    static func fromVisionResult(id: UUID = UUID(), boundingBox: CGRect, confidence: Double, thumbnail: UIImage? = nil) -> DetectedObject {
        return DetectedObject(
            boundingBox: boundingBox,
            confidence: confidence,
            category: .other, // é»˜è®¤ç±»åˆ«
            estimatedSize: CGSize(width: boundingBox.width, height: boundingBox.height),
            recognitionResult: nil,
            thumbnail: thumbnail
        )
    }
}

/// å¯¹è±¡ç±»å‹
enum ObjectType {
    case rectangular
    case contour
    case text
    case circular
    case irregular
}

/// å¯¹è±¡ç‰¹å¾
struct ObjectFeatures {
    let aspectRatio: Double
    let area: Double
    let perimeter: Double
    let complexity: Double
    
    init(aspectRatio: Double = 1.0, area: Double = 0.0, perimeter: Double = 0.0, complexity: Double = 0.5) {
        self.aspectRatio = aspectRatio
        self.area = area
        self.perimeter = perimeter
        self.complexity = complexity
    }
}

/// å¯¹è±¡æ£€æµ‹ç»“æœ
struct ObjectDetectionResult {
    let objects: [DetectedObject]
    let groups: [ObjectGroup]
    let overallConfidence: Double
    let sceneComplexity: SceneComplexity
    let processingTime: TimeInterval
}

/// å¯¹è±¡ç»„
struct ObjectGroup: Identifiable {
    let id: Int
    let objects: [DetectedObject]
    let type: ObjectType
    let confidence: Float
}

/// åœºæ™¯å¤æ‚åº¦
enum SceneComplexity {
    case simple
    case moderate
    case complex
    
    var displayName: String {
        switch self {
        case .simple: return "ç®€å•"
        case .moderate: return "ä¸­ç­‰"
        case .complex: return "å¤æ‚"
        }
    }
    
    var icon: String {
        switch self {
        case .simple: return "circle"
        case .moderate: return "circle.lefthalf.filled"
        case .complex: return "circle.fill"
        }
    }
    
    var color: Color {
        switch self {
        case .simple: return .green
        case .moderate: return .orange
        case .complex: return .red
        }
    }
}

/// åŒºåŸŸæå–ç­–ç•¥
enum RegionExtractionStrategy {
    case automatic
    case largestFirst
    case highestConfidence
    case centerFocused
}

/// æå–çš„åŒºåŸŸ
struct ExtractedRegion: Identifiable {
    let id: Int
    let image: UIImage
    let boundingBox: CGRect
    let confidence: Float
    let type: ObjectType
    let features: ObjectFeatures
}

/// èƒŒæ™¯åˆ†ç¦»ç»“æœ
struct BackgroundSeparationResult {
    let originalImage: UIImage
    let foregroundMask: UIImage
    let backgroundMask: UIImage?
    let separationQuality: Double
}

// MARK: - æ‰©å±•

extension ObjectType {
    var displayName: String {
        switch self {
        case .rectangular:
            return "çŸ©å½¢"
        case .contour:
            return "è½®å»“"
        case .text:
            return "æ–‡æœ¬"
        case .circular:
            return "åœ†å½¢"
        case .irregular:
            return "ä¸è§„åˆ™"
        }
    }
}

